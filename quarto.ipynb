{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2_p6cn1BoM3y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thiziri-Hafir/Donnees_Massives/blob/main/quarto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "title: \"Projet : Changement de production de café en fonction du climat au Brésil\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "jupyter: python3\n",
        "---"
      ],
      "metadata": {
        "id": "yV5ppd0aqC49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "HWInYt5nT7vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the data"
      ],
      "metadata": {
        "id": "zVBfQxoCVXdB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB1xk38dTrBN"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "import pandas as pd\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "SparkContext.setSystemProperty('spark.executor.memory', '8g')\n",
        "SparkContext.setSystemProperty('spark.driver.memory', '45G')\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.appName(\"Python Spark\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/jldbc/coffee-quality-database/master/data/arabica_data_cleaned.csv\"\n",
        "raw_arabica = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "l9lkq3ObU7gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# Auxiliar functions\n",
        "def equivalent_type(f):\n",
        "    \"\"\" \n",
        "         Function that changes the input Python type to PySpark type\n",
        "    \"\"\"\n",
        "    if f == 'datetime64[ns]': return TimestampType()\n",
        "    elif f == 'int64': return LongType()\n",
        "    elif f == 'int32': return IntegerType()\n",
        "    elif f == 'float64': return DoubleType()\n",
        "    elif f == 'float32': return FloatType()\n",
        "    else: return StringType()\n",
        "\n",
        "def define_structure(string, format_type):\n",
        "    \"\"\" \n",
        "         Function that define the structure of the input\n",
        "    \"\"\"\n",
        "    try: typo = equivalent_type(format_type)\n",
        "    except: typo = StringType()\n",
        "    return StructField(string, typo)\n",
        "\n",
        "# Given pandas dataframe, it will return a spark's dataframe.\n",
        "def pandas_to_spark(pandas_df):\n",
        "    \"\"\" \n",
        "         Function that transforms an input pandas dataframe to a spark dataframe\n",
        "    \"\"\"\n",
        "    columns = list(pandas_df.columns)\n",
        "    types = list(pandas_df.dtypes)\n",
        "    struct_list = []\n",
        "    for column, typo in zip(columns, types): \n",
        "      struct_list.append(define_structure(column, typo))\n",
        "    p_schema = StructType(struct_list)\n",
        "    return spark.createDataFrame(pandas_df, p_schema)"
      ],
      "metadata": {
        "id": "JT1QNG7yU_S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaate a spark dataframe from our initial pandas dataframe \n",
        "\n",
        "raw_arabica[['Variety']]= raw_arabica[['Variety']].fillna('unknown')\n",
        "df_arabica = pandas_to_spark(raw_arabica)  "
      ],
      "metadata": {
        "id": "u2Gds8tjVCkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica.show(10)"
      ],
      "metadata": {
        "id": "FBTYvWeWA9pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic structural transformations and harmonization"
      ],
      "metadata": {
        "id": "x_-mzrIgVcQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Renaming columns and selecting the columns and rows of interest"
      ],
      "metadata": {
        "id": "KE1RpgPaV8YR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the next cell, we rename the columns to facilitate their use.\n"
      ],
      "metadata": {
        "id": "v-w3xAVODkKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempList = [] #Edit01\n",
        "for col in df_arabica.columns:\n",
        "        new_name = col.strip()\n",
        "        new_name = \"\".join(new_name.split())\n",
        "        new_name = new_name.replace('.','_') # EDIT\n",
        "        tempList.append(new_name) #Edit02\n",
        "print(tempList) #Just for the sake of it #Edit03\n",
        "\n",
        "df_arabica = df_arabica.toDF(*tempList) #Edit04"
      ],
      "metadata": {
        "id": "42Ntf6-3VE90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We decided to focus on Brazil as it is one of the biggest coffee producer and presents interesting geoclimatic features and diversity"
      ],
      "metadata": {
        "id": "VcAZCNvSYQsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica = df_arabica.filter(df_arabica[\"Country_of_Origin\"]=='Brazil')\\\n",
        "          .distinct()\\\n",
        "          .select([\"Farm_name\",\"Altitude\",\"Variety\",\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\",\"Balance\",\"Uniformity\",\"Clean_Cup\",\"Sweetness\",\"Total_Cup_Points\",\"altitude_mean_meters\"])\n",
        "df_arabica.show(100, 100)"
      ],
      "metadata": {
        "id": "8bupiicSVOGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_arabica = df_arabica.withColumn('Farm_name', regexp_replace(col('Farm_name'), \"/\", \"_\"))"
      ],
      "metadata": {
        "id": "aoyerjXoe_ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We drop all rows with where altitude_mean_meters==NaN\n",
        "df_arabica = df_arabica.na.drop(subset=[\"altitude_mean_meters\"]) "
      ],
      "metadata": {
        "id": "aYw5eX0GDYOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica.show(10,10)"
      ],
      "metadata": {
        "id": "wYlLw3A0MNHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### At first sight, we can notice that we need to harmonize the Altitude column values and link each Farm_name to its position.\n"
      ],
      "metadata": {
        "id": "wvMFtbhxW7PG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Harmonizing the altitude column"
      ],
      "metadata": {
        "id": "iLx9HyzwXRto"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZIYqUlFXY7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linking Farm_names to actual longitudes and latitudes"
      ],
      "metadata": {
        "id": "cCoucEK9Xgxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### We created by hand a dataset with the position of the fields of each Farm_name and performed a simple outer_join"
      ],
      "metadata": {
        "id": "9Vz3Us9hXmN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_farms = spark.createDataFrame(\n",
        "    [\n",
        "        (\"fazenda rio verde\",-21.877600079894428, -45.17833587173798 ), \n",
        "        (\"fazenda do lobo\", -20.05845833645814, -45.551377369807916),\n",
        "        (\"fazenda grota funda\",-4.498676298642221, -46.01438009152326),\n",
        "        (\"sitio claro\",-12.404400112670487, -57.0307320652044),\n",
        "        (\"santa alina\",-21.76121880758086, -46.674253002625804),\n",
        "        (\"fazenda chamusca\",-21.4532483711391, -45.22708818550831),\n",
        "        (\"santa maria\",-16.609194745742165, -46.98365752985455),\n",
        "        (\"capoeirinha\",-18.64698614414741, -45.796849953979795),\n",
        "        (\"fazenda do sertao\",-22.09933939187727, -45.18968007378277),\n",
        "        (\"santa fé 2\",-17.582654936016926, -47.2198752950817),\n",
        "        (\"café do paraíso\",-22.094568087843687, -45.155496432162685),\n",
        "        (\"cachoeira da grama farm\",-21.76626556295618, -46.702161544954144),\n",
        "        (\"são francisco da serra\",-22.629913000779446, -44.601043902591805),\n",
        "        (\"fazenda jericó\",-18.676315608302055, -45.70281563093488),\n",
        "        (\"sertao farm\",-22.099418916815903, -45.18965861611114),\n",
        "        (\"campo das flores\",-20.312258124962906, -43.28548394936318),\n",
        "        (\"olhos d'agua\",-18.63831446703355, -46.952789277527444),\n",
        "        (\"fazenda serra de três barras\",-19.560780988980817, -46.579303497451384),\n",
        "        (\"fazenda pantano\",-18.631997524421426, -46.82473127385452),\n",
        "        (\"pereira estate coffee\",-22.112480964214626, -45.15508902245408),\n",
        "        (\"rio verde\",-21.940510105475326, -45.176192869009476),\n",
        "        (\"sitío são geraldo\",-22.59528143237296, -46.66759241371165),\n",
        "        (\"fazenda baipendi\",-21.45008093579659, -46.8357381855336),\n",
        "        (\"água limpa\",-21.44645605895183, -46.82635044153258),\n",
        "        (\"fazenda kaquend\",-21.435236392716707, -46.83244978479159),\n",
        "        (\"fazenda santo antonio\",-21.40862617568116, -46.80560442679252),\n",
        "        (\"fazenda vista alegre\",-21.44237673402853, -46.818513026788274),\n",
        "        (\"fazenda recreio\",-21.780100162105256, -46.67880344388111),\n",
        "        (\"fazenda capoeirnha\",-21.761009557830032, -46.67507912298348),\n",
        "        (\"pantano\",-21.444638601462618, -46.81747769417689),\n",
        "        (\"fazenda são sebastião\",-21.444863288363614, -46.827235570452125),\n",
        "        (\"santa bárbara\",-18.52732198399872, -47.569893903127564),\n",
        "        (\"santa mariana\",-23.19046310851501, -50.55948683365515),\n",
        "        (\"sertao\",-22.095760723175886, -45.189755175672296),\n",
        "        (\"são rafael_ ra/ras certified\",-22.784292492565246, -47.032534461666536),\n",
        "        (\"sitío santa luzia\",-22.366016295045306, -46.47371725096838),\n",
        "        (\"fazenda são josé mirante\",-22.785019797545694, -47.03177457322967),\n",
        "        (\"cianorte\",-22.774138613223663, -47.02968245276757),\n",
        "        (\"juliana\",-21.46270024286904, -46.832515362350975),\n",
        "        (\"sitío corrego da olaria/são caetano\",-22.745464486282955, -47.0338567362583),\n",
        "        (\"fazenda serra negra\",-21., -46.674253002625804),\n",
        "        (\"fazendas klem ltda\",-20.27591897959779, -41.876604035124465),\n",
        "        (\"castelhana farm\",-18.922960557030457, -47.45831617257145),\n",
        "        (\"leticia farm\",-19.807319369835636, -42.215697182335234),\n",
        "        (\"helena\",-22.107657064931225, -48.32067672583973),\n",
        "        (\"caxambu\",-21.339808722609096, -45.42201735838091),\n",
        "    ],\n",
        "    [\"Farm_name\", \"lat\",\"long\"]  # we add column names here\n",
        ")"
      ],
      "metadata": {
        "id": "OEVstVcWXvKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the two dataframes to made one \n",
        "df_arabica = df_arabica.join(df_farms, on=['Farm_name'], how='left_outer')"
      ],
      "metadata": {
        "id": "yfpoxlabXwzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica.show(10)"
      ],
      "metadata": {
        "id": "kdU0wnUtYjcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We then filter the coffee to keep only those whose origin is known (Farm_name)."
      ],
      "metadata": {
        "id": "U4tG1Tj4aSMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica = df_arabica.filter(df_arabica.Farm_name != \"NaN\")\n",
        "df_arabica.show(10)"
      ],
      "metadata": {
        "id": "LNX4DwUXahX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We also replace NaN values in the Variety column by \"Unknonwn\" as the information about the variety is missing."
      ],
      "metadata": {
        "id": "VHm_XPDjJQGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica = df_arabica.replace(float('nan'), None)\n",
        "\n",
        "\n",
        "df_arabica.show(10)"
      ],
      "metadata": {
        "id": "8lOqDuy2alSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and plotting"
      ],
      "metadata": {
        "id": "B56DhNgJYtod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now that we cleaned and structured the data, we will explore them to fully understand them and get more details abour their behavour. "
      ],
      "metadata": {
        "id": "LPxQfwvLNF3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Location of coffee farms "
      ],
      "metadata": {
        "id": "9NSDdvHxMyNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### On the map below, we can see the projection of the farms that produce coffee in Brazil. We can see at first sight that they are mainly in the south east of the country, on the side of the Atlantic Ocean. This gives us a first idea of the meteorological conditions necessary for this production,since the south-east is a region with a subtropical climate. The summer can be very hot, even stifling, and there are many tropical rains, as sudden as they can be violent, especially in Rio and São Paulo. Winter, from June to September, is rather mild, with temperatures between 12 and 25 degrees."
      ],
      "metadata": {
        "id": "EjPjNbIiKIsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter_mapbox(df_arabica.toPandas(), lat=\"lat\", lon=\"long\", hover_name=\"Farm_name\", hover_data=[\"altitude_mean_meters\",], color_discrete_sequence=[\"fuchsia\"], zoom=3, height=300)\n",
        "fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_rXD9XPk82c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The correlation between the different taste of coffee variables "
      ],
      "metadata": {
        "id": "T5e3HvTNMIpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rédiger  COOOOOOOOOOORRREEEEEEEEEEEEELLAAAAAAAAAAATION\n",
        "\n"
      ],
      "metadata": {
        "id": "M69BIHuVNdpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica.groupBy('Variety')\\\n",
        "          .count().alias(\"count\")\\\n",
        "          .show()"
      ],
      "metadata": {
        "id": "GAwfXpiPOuNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Seaborn library, we plot the individuals on a dual axis to see if there are overall correlations between the taste variables (aroma, flavor, aftertaste, acidity, sweetness). We can also observe if individuals of the same variety share the same correlation on this axis. Finally we can observe how the varieties are distributed on the correlation axis."
      ],
      "metadata": {
        "id": "_kAws9vtG9tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "g = sns.PairGrid(df_arabica.toPandas(), vars=['Aroma','Flavor','Aftertaste','Acidity','Sweetness'],\n",
        "                 hue='Variety', palette='RdBu_r')\n",
        "g.map(plt.scatter, alpha=0.4)\n",
        "g.add_legend();"
      ],
      "metadata": {
        "id": "VVIjr9GzUJgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative visualisation"
      ],
      "metadata": {
        "id": "PJ-WA6oTNXZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install seaborn --upgrade \n",
        "#if there are errors : upgrade seaborn then restart kernel\n",
        "g = sns.PairGrid(df_arabica.toPandas(), vars=['Aroma','Flavor','Aftertaste','Acidity','Sweetness'], hue='Variety', palette = \"deep\")\n",
        "g.map_upper(sns.scatterplot)\n",
        "g.map_lower(sns.kdeplot, warn_singular=False)\n",
        "g.map_diag(sns.kdeplot, warn_singular=False, lw = 3)\n",
        "g.add_legend()"
      ],
      "metadata": {
        "id": "OnmuuuC_-38x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We may need more individuals to find a clear pattern."
      ],
      "metadata": {
        "id": "hXC0kVGzSp6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taste profile and scoring relation "
      ],
      "metadata": {
        "id": "DVAzLN2GYxVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the section below, we will see how the different tastes of coffee influence the rating of Total_Cup_Score"
      ],
      "metadata": {
        "id": "xnwnNbS-bfIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the features vector which are : Aroma, Flavor, Aftertaste, Acidity, Body, Balance, Uniformity, Clean_Cup, Sweetnes."
      ],
      "metadata": {
        "id": "pCXx2cCUdTVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorAssembler = VectorAssembler(inputCols = [\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\", \"Balance\", \"Clean_Cup\", \"Uniformity\",\"Sweetness\"], outputCol = 'features')\n",
        "vec_df_arabica = vectorAssembler.transform(df_arabica)"
      ],
      "metadata": {
        "id": "9B70pLp0bd6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train test splitting"
      ],
      "metadata": {
        "id": "MeVxFFA5dQaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_taste,test_taste  = vec_df_arabica.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "8Dnb45XwdPoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### LR model"
      ],
      "metadata": {
        "id": "ZDjMHxfXdj1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol='Total_Cup_Points', maxIter=10)\n",
        "lr_model = lr.fit(train_taste)\n",
        "print(\"Coefficients: \" + str(lr_model.coefficients[:5])+ \"\\n\"+ str(lr_model.coefficients[5:]))\n",
        "print(\"Intercept: \" + str(lr_model.intercept))"
      ],
      "metadata": {
        "id": "U_W6uJA5dAgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the train data \n",
        "print(\"MSE: \", lr_model.summary.meanSquaredError)\n",
        "print(\"MAE: \", lr_model.summary.meanAbsoluteError)\n",
        "print(\"R-squared: \", lr_model.summary.r2) "
      ],
      "metadata": {
        "id": "qNP-xIbP4uxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting and evaluating the model"
      ],
      "metadata": {
        "id": "Uzmm7PSCealT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_predictions = lr_model.transform(test_taste)\n",
        "lr_predictions.select(\"prediction\",\"Total_Cup_Points\",\"features\").show(5)"
      ],
      "metadata": {
        "id": "dvHB_lD0eiD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test data \n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
        "                 labelCol=\"Total_Cup_Points\")\n",
        "\n",
        "print(\"MAE on test data = %g\" % lr_evaluator.evaluate(lr_predictions, {lr_evaluator.metricName: \"mae\"}))\n",
        "print(\"MSE on test data = %g\" % lr_evaluator.evaluate(lr_predictions, {lr_evaluator.metricName: \"mse\"}))\n",
        "print(\"R-squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions, {lr_evaluator.metricName: \"r2\"}))\n"
      ],
      "metadata": {
        "id": "eKrAhrZIfB3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Th R squared of our model is very high that means that the variation of tastes variables explains very well the note given for a coffee. In the other hand, our model fits quite well the data."
      ],
      "metadata": {
        "id": "PA6mxGR3fSIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In the graph below, we can see that the prediction values curve is almost superimposed on the original values curve"
      ],
      "metadata": {
        "id": "y05K935YztVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ax = range(0,lr_predictions.count())\n",
        "y_pred = lr_predictions.select(\"prediction\").collect()\n",
        "y_orig = lr_predictions.select(\"Total_Cup_Points\").collect()"
      ],
      "metadata": {
        "id": "2F94FxaTyRqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.plot(x_ax, y_orig, label=\"Total_Cup_Points\")\n",
        "plt.plot(x_ax, y_pred, label=\"prediction\")\n",
        "plt.title(\"Real notes on the test data and the predicted ones\")\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.legend(loc='best',fancybox=True, shadow=True)\n",
        "plt.grid(True)\n",
        "plt.show()  \n",
        " \n"
      ],
      "metadata": {
        "id": "NU5WAyvJfpwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variety and scoring relation"
      ],
      "metadata": {
        "id": "_0VWZKVTY8kL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For this one we will just use visualizations to see the variation of coffee grade according to the variet."
      ],
      "metadata": {
        "id": "xNQaoih5f07i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = df_arabica.groupBy(\"Variety\").mean(\"Total_Cup_Points\")\n",
        "var.show()"
      ],
      "metadata": {
        "id": "gBcQiNAFZAEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.bar(var.toPandas(), x='Variety', y='avg(Total_Cup_Points)')"
      ],
      "metadata": {
        "id": "UP7tnDvCJz5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.lineplot(x=\"Variety\", y='avg(Total_Cup_Points)', data=var.toPandas()).set_title('Variation of the coffee grade according to the variety')"
      ],
      "metadata": {
        "id": "rneAG8EfGVVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Not a very convincing plot, the Total_Cup_Points are very close (in the 80-90 range) and variety doesn't seem to matter that much"
      ],
      "metadata": {
        "id": "YV1Wp3-qkD9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Farm and scoring relation"
      ],
      "metadata": {
        "id": "kcQRu2pwZAPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "farmr = df_arabica.groupBy(\"Farm_name\").mean(\"Total_Cup_Points\")\n",
        "farmr.show()"
      ],
      "metadata": {
        "id": "a1qhNoYzmJRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.bar(farmr.toPandas().sort_values(by=['avg(Total_Cup_Points)']), x='Farm_name', y='avg(Total_Cup_Points)')"
      ],
      "metadata": {
        "id": "Uk1abBQCmakC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Once again the plot is uninteresting, we can try to scale Total_Cup_Points to see more clearly (and with it let's do it on the tastes column since they suffer the same problem)"
      ],
      "metadata": {
        "id": "2_p6cn1BoM3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing"
      ],
      "metadata": {
        "id": "I0paRqsloYsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf"
      ],
      "metadata": {
        "id": "eFnnRJcooas7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n",
        "df_arabica_scaled = df_arabica\n",
        "\n",
        "for i in [\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\",\"Balance\",\"Total_Cup_Points\"]:\n",
        "    # VectorAssembler Transformation - Converting column to vector type\n",
        "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
        "\n",
        "    # MinMaxScaler Transformation\n",
        "    scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
        "\n",
        "    # Pipeline of VectorAssembler and MinMaxScaler\n",
        "    pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "    # Fitting pipeline on dataframe\n",
        "    df_arabica_scaled = pipeline.fit(df_arabica_scaled).transform(df_arabica_scaled).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n",
        "\n",
        "print(\"After Scaling :\")\n",
        "df_arabica_scaled.show(5)"
      ],
      "metadata": {
        "id": "6jyses5EoLxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "source : https://stackoverflow.com/questions/40337744/scalenormalise-a-column-in-spark-dataframe-pyspark"
      ],
      "metadata": {
        "id": "QrPiRf-nqVMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Back to Exploration"
      ],
      "metadata": {
        "id": "rVBT1T4vsNub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's try again the previous plots"
      ],
      "metadata": {
        "id": "Gb_aMJwxsZsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variety"
      ],
      "metadata": {
        "id": "-qD3fjJJspzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = df_arabica_scaled.groupBy(\"Variety\").mean(\"Total_Cup_Points_Scaled\")\n",
        "px.bar(var.toPandas(), x='Variety', y='avg(Total_Cup_Points_Scaled)')"
      ],
      "metadata": {
        "id": "tb6jmXElsePZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.lineplot(x=\"Variety\", y='avg(Total_Cup_Points_Scaled)', data=var.toPandas()).set_title('Variation of the coffee grade according to the variety')"
      ],
      "metadata": {
        "id": "EUAEFdcwJlC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOOOOOOOOOOOOOOOOOOOO DOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO"
      ],
      "metadata": {
        "id": "mAHj_A4ItRGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Farms"
      ],
      "metadata": {
        "id": "KQ_GJ3HWsnqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "farmr = df_arabica_scaled.groupBy(\"Farm_name\").mean(\"Total_Cup_Points_Scaled\")\n",
        "px.bar(farmr.toPandas().sort_values(by=['avg(Total_Cup_Points_Scaled)']), x='Farm_name', y='avg(Total_Cup_Points_Scaled)')"
      ],
      "metadata": {
        "id": "yK10qWfnshxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Way clearer"
      ],
      "metadata": {
        "id": "P6wQhh1Gs9N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We can notice that farms are more important offer more distinction than variety, we will see furthermore"
      ],
      "metadata": {
        "id": "naGA7j8YwcFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From now on we will use only the scaled version"
      ],
      "metadata": {
        "id": "CyhKDPdEtYwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arabica = df_arabica_scaled\n",
        "\n",
        "cols = (\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\",\"Balance\",\"Total_Cup_Points\")\n",
        "df_arabica = df_arabica.drop(*cols)\n",
        "for i in [\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\",\"Balance\",\"Total_Cup_Points\"]:\n",
        "                   df_arabica = df_arabica.withColumnRenamed(i+\"_Scaled\", i)\n",
        "\n",
        "df_arabica.show()\n",
        "df_arabica.printSchema()"
      ],
      "metadata": {
        "id": "0uzHwEqgtfng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Farms all of fame and their strengths"
      ],
      "metadata": {
        "id": "QIjCRSP9mJb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Since farms seem interesting we can plot radar plots of the taste they offer (meaned).\n",
        "#### We will focus on the most renowed farms"
      ],
      "metadata": {
        "id": "JvBejSPCwtd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "hof = df_arabica.groupBy(\"Farm_name\").mean(\"Total_Cup_Points\").sort(desc(\"avg(Total_Cup_Points)\"))\n",
        "hof.show(6)"
      ],
      "metadata": {
        "id": "kZ_f6k13ZGM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will take the top 3"
      ],
      "metadata": {
        "id": "I-YXFI_OyLFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAIIIIIIIIIRE"
      ],
      "metadata": {
        "id": "sOfl1Fdp2gWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "li = hof.select(\"Farm_name\").take(3)[:3]"
      ],
      "metadata": {
        "id": "LdnW7A0KysHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "li"
      ],
      "metadata": {
        "id": "5hAG3CRQ0swA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "li = [\"fazenda kaquend\",\"fazenda recreio\",\"sitío são geraldo\",\"sitio claro\",\"fazenda grota funda\"]"
      ],
      "metadata": {
        "id": "uPOW_b_60ZpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meaner par farm"
      ],
      "metadata": {
        "id": "tMuzaC6gBLiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hof = df_arabica.filter(df_arabica.Farm_name.isin(li))\n",
        "df_hof.show()"
      ],
      "metadata": {
        "id": "05RgOmqDxgCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import mean\n",
        "\n",
        "categories = [\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\",\"Balance\"]\n",
        "\n",
        "df_hof_pd = df_hof.select([\"Farm_name\",\"Aroma\",\"Flavor\",\"Aftertaste\",\\\n",
        "                   \"Acidity\",\"Body\",\"Balance\"]).toPandas().set_index('Farm_name')\n",
        "\n",
        "\n",
        "df_mean_pd = df_arabica.select(mean(\"Aroma\"), mean(\"Flavor\")\\\n",
        "                               , mean(\"Aftertaste\"), mean(\"Acidity\"), mean(\"Body\"), mean(\"Balance\"))\\\n",
        "                               .toPandas()\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for g in df_hof_pd.index:\n",
        "    fig.add_trace(go.Scatterpolar(\n",
        "        r = df_hof_pd.loc[g].values,\n",
        "        theta = categories,\n",
        "        fill = \"toself\",\n",
        "        name = f'{g}'\n",
        "    ))\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatterpolar(\n",
        "        r = df_mean_pd.values,\n",
        "        theta = categories,\n",
        "        fill = \"toself\",\n",
        "        name = f'MEAN'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "  polar=dict(\n",
        "    radialaxis=dict(\n",
        "      visible=False,\n",
        "      range=[0, 1]\n",
        "    )),\n",
        "  showlegend=False\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TAukSS8o3I3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "D3xg7iOa-UHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install pyproj"
      ],
      "metadata": {
        "id": "Tp5GwEMuAH3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import rasterio.plot\n",
        "import pyproj\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jfkKHYbkwesg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "f, axarr = plt.subplots(2,2)\n",
        "\n",
        "\n",
        "for i,itif in enumerate( [\"avgtemp.tif\", \"prec.tif\", \"srac.tif\", \"vapr.tif\"]) :\n",
        "  with rasterio.open(\"/content/gdrive/MyDrive/donmass_proj/\"+itif) as src:\n",
        "    img = src.read(1)\n",
        "    #print(src.crs)\n",
        "    if(i<2):\n",
        "      a = 0\n",
        "    else:\n",
        "      a = 1\n",
        "      i -=2 \n",
        "    pos = src.index(-52.196283130028455,-13.574677798648072) #long lat \n",
        "    axarr[a][i].imshow(img[pos[0]-2200:pos[0]+2200,pos[1]-2200:pos[1]+2200]) "
      ],
      "metadata": {
        "id": "rV2Pwr6Kvxs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P35w0uCv6c2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOS_8g6rN3Ue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}